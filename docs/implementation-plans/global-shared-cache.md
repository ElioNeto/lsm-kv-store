# Plano de ImplementaÃ§Ã£o: Global Shared Block Cache

**Issue:** #35  
**Branch:** `feature/global-shared-cache`  
**Prioridade:** HIGH  
**Estimativa:** 1-2 dias  

---

## ğŸ“‹ Objetivo

Implementar um cache de blocos global compartilhado entre todas as instÃ¢ncias de `SstableReader`, reduzindo o consumo de memÃ³ria de `O(num_sstables * cache_size)` para `O(cache_size)`.

## ğŸ¯ Problema Atual

Cada `SstableReader` possui seu prÃ³prio `LruCache<u64, Vec<u8>>` de tamanho configurado (ex: 64MB). Com mÃºltiplas SSTables abertas:

```
100 SSTables Ã— 64MB = 6.4GB de memÃ³ria
```

Isso desperdiÃ§a memÃ³ria e nÃ£o respeita o limite global de cache configurado.

## âœ… SoluÃ§Ã£o Proposta

Criar um cache global Ãºnico compartilhado via `Arc<Mutex<...>>` que armazena blocos de todas as SSTables.

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LsmEngine                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   GlobalBlockCache (Arc)          â”‚  â”‚
â”‚  â”‚   LruCache<CacheKey, Arc<Vec>>    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â–²           â–²           â–²     â”‚
â”‚           â”‚           â”‚           â”‚     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”â”‚
â”‚  â”‚SSTableReaderâ”‚ â”‚SSTable  â”‚ â”‚SSTable â”‚â”‚
â”‚  â”‚   (Arc)     â”‚ â”‚Reader   â”‚ â”‚Reader  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Design Detalhado

### 1. Estrutura `CacheKey`

**Problema:** Chave atual Ã© apenas `u64` (offset do bloco). Com mÃºltiplos arquivos, colisÃµes sÃ£o inevitÃ¡veis.

**SoluÃ§Ã£o:** Chave composta identificando arquivo + offset.

```rust
// src/storage/cache.rs
use std::hash::{Hash, Hasher};
use std::path::PathBuf;
use std::collections::hash_map::DefaultHasher;

#[derive(Debug, Clone, PartialEq, Eq, Hash)]
pub struct CacheKey {
    file_id: u64,      // Hash do PathBuf
    block_offset: u64, // Offset do bloco no arquivo
}

impl CacheKey {
    pub fn new(path: &PathBuf, offset: u64) -> Self {
        let mut hasher = DefaultHasher::new();
        path.hash(&mut hasher);
        let file_id = hasher.finish();
        
        Self {
            file_id,
            block_offset: offset,
        }
    }
}
```

**Alternativa considerada:** Usar `PathBuf` diretamente como chave.
- âŒ Overhead de memÃ³ria (paths podem ser longos)
- âŒ ComparaÃ§Ã£o mais lenta
- âœ… Usar hash Ã© mais eficiente

### 2. Estrutura `GlobalBlockCache`

```rust
// src/storage/cache.rs
use lru::LruCache;
use std::num::NonZeroUsize;
use std::sync::{Arc, Mutex};

pub struct GlobalBlockCache {
    cache: Mutex<LruCache<CacheKey, Arc<Vec<u8>>>>,
}

impl GlobalBlockCache {
    pub fn new(capacity_mb: usize, block_size: usize) -> Arc<Self> {
        let capacity_bytes = capacity_mb * 1024 * 1024;
        let num_blocks = (capacity_bytes / block_size).max(1);
        let capacity = NonZeroUsize::new(num_blocks).unwrap();
        
        Arc::new(Self {
            cache: Mutex::new(LruCache::new(capacity)),
        })
    }
    
    pub fn get(&self, key: &CacheKey) -> Option<Arc<Vec<u8>>> {
        let mut cache = self.cache.lock().unwrap();
        cache.get(key).cloned()
    }
    
    pub fn put(&self, key: CacheKey, value: Vec<u8>) {
        let mut cache = self.cache.lock().unwrap();
        cache.put(key, Arc::new(value));
    }
    
    pub fn clear(&self) {
        let mut cache = self.cache.lock().unwrap();
        cache.clear();
    }
    
    // MÃ©todo para estatÃ­sticas (opcional)
    pub fn stats(&self) -> CacheStats {
        let cache = self.cache.lock().unwrap();
        CacheStats {
            len: cache.len(),
            cap: cache.cap().get(),
        }
    }
}

#[derive(Debug, Clone)]
pub struct CacheStats {
    pub len: usize,
    pub cap: usize,
}
```

**DecisÃ£o de Design: `Arc<Vec<u8>>` em vez de `Vec<u8>`**
- âœ… Evita clonagem de dados ao retornar do cache
- âœ… Permite mÃºltiplas referÃªncias ao mesmo bloco
- âœ… Cache hit fica O(1) sem cÃ³pia

### 3. RefatoraÃ§Ã£o do `SstableReader`

**Antes:**
```rust
pub struct SstableReader {
    block_cache: LruCache<u64, Vec<u8>>,  // Cache prÃ³prio
    // ...
}
```

**Depois:**
```rust
// src/storage/reader.rs
use crate::storage::cache::{GlobalBlockCache, CacheKey};

pub struct SstableReader {
    metadata: MetaBlock,
    bloom_filter: Bloom<[u8]>,
    file: File,
    block_cache: Arc<GlobalBlockCache>,  // âœ… Cache compartilhado
    path: PathBuf,
    config: StorageConfig,
}

impl SstableReader {
    pub fn open(
        path: PathBuf,
        config: StorageConfig,
        block_cache: Arc<GlobalBlockCache>,  // âœ… InjeÃ§Ã£o de dependÃªncia
    ) -> Result<Self> {
        // ... cÃ³digo existente de leitura do arquivo ...
        
        Ok(Self {
            metadata,
            bloom_filter,
            file,
            block_cache,  // Usa o cache compartilhado
            path,
            config,
        })
    }
    
    fn read_block(&mut self, block_meta: &BlockMeta) -> Result<Vec<u8>> {
        let cache_key = CacheKey::new(&self.path, block_meta.offset);
        
        // Tentar obter do cache
        if let Some(cached) = self.block_cache.get(&cache_key) {
            return Ok((*cached).clone());  // Arc -> Vec clone
        }
        
        // Cache miss - ler do disco
        let block_data = self.read_and_decompress_block(block_meta)?;
        
        // Armazenar no cache global
        self.block_cache.put(cache_key, block_data.clone());
        
        Ok(block_data)
    }
}
```

### 4. AtualizaÃ§Ã£o do `LsmEngine`

```rust
// src/core/engine.rs
use crate::storage::cache::GlobalBlockCache;

pub struct LsmEngine {
    pub(crate) memtable: Mutex<MemTable>,
    pub(crate) wal: WriteAheadLog,
    pub(crate) sstables: Mutex<Vec<SstableReader>>,
    pub(crate) block_cache: Arc<GlobalBlockCache>,  // âœ… Novo campo
    pub(crate) dir_path: PathBuf,
    pub(crate) config: LsmConfig,
}

impl LsmEngine {
    pub fn new(config: LsmConfig) -> Result<Self> {
        std::fs::create_dir_all(&config.core.dir_path)?;
        
        // âœ… Criar cache global Ãºnico
        let block_cache = GlobalBlockCache::new(
            config.storage.block_cache_size_mb,
            config.storage.block_size,
        );
        
        let wal = WriteAheadLog::new(&config.core.dir_path)?;
        let wal_records = wal.recover()?;
        
        let mut sstables = Vec::new();
        for entry in std::fs::read_dir(&config.core.dir_path)? {
            let entry = entry?;
            let path = entry.path();
            if path.extension().is_some_and(|ext| ext == "sst") {
                // âœ… Passar cache para cada reader
                match SstableReader::open(
                    path.clone(),
                    config.storage.clone(),
                    Arc::clone(&block_cache),  // Compartilhar cache
                ) {
                    Ok(sst) => sstables.push(sst),
                    Err(e) => warn!("Failed to load SSTable {}: {}", path.display(), e),
                }
            }
        }
        
        // ... resto do cÃ³digo ...
        
        Ok(Self {
            memtable: Mutex::new(memtable),
            wal,
            sstables: Mutex::new(sstables),
            block_cache,  // âœ… Armazenar referÃªncia
            dir_path: config.core.dir_path.clone(),
            config,
        })
    }
    
    fn flush(&self) -> Result<()> {
        // ... cÃ³digo de flush ...
        
        // âœ… Passar cache ao abrir novo SSTable
        let reader = SstableReader::open(
            sst_path,
            self.config.storage.clone(),
            Arc::clone(&self.block_cache),
        )?;
        
        // ...
    }
}
```

---

## ğŸ”§ Ordem de ImplementaÃ§Ã£o

### **Fase 1: Estrutura Base** (2-3 horas)

1. âœ… Criar arquivo `src/storage/cache.rs`
2. âœ… Implementar `CacheKey` com testes unitÃ¡rios
3. âœ… Implementar `GlobalBlockCache` com testes unitÃ¡rios
4. âœ… Adicionar `pub mod cache;` em `src/storage/mod.rs`

**Testes:**
```rust
#[test]
fn test_cache_key_uniqueness() {
    let path1 = PathBuf::from("/data/sst1.sst");
    let path2 = PathBuf::from("/data/sst2.sst");
    
    let key1 = CacheKey::new(&path1, 0);
    let key2 = CacheKey::new(&path2, 0);
    
    assert_ne!(key1, key2);  // Diferentes arquivos
}

#[test]
fn test_cache_key_same_file() {
    let path = PathBuf::from("/data/sst1.sst");
    
    let key1 = CacheKey::new(&path, 0);
    let key2 = CacheKey::new(&path, 4096);
    
    assert_ne!(key1, key2);  // Diferentes offsets
    assert_eq!(key1.file_id, key2.file_id);  // Mesmo arquivo
}

#[test]
fn test_global_cache_basic() {
    let cache = GlobalBlockCache::new(1, 4096);  // 1MB, blocos de 4KB
    
    let key = CacheKey::new(&PathBuf::from("test.sst"), 0);
    let data = vec![1, 2, 3, 4];
    
    cache.put(key.clone(), data.clone());
    
    let retrieved = cache.get(&key).unwrap();
    assert_eq!(*retrieved, data);
}
```

### **Fase 2: RefatoraÃ§Ã£o do Reader** (2-3 horas)

1. âœ… Adicionar campo `Arc<GlobalBlockCache>` em `SstableReader`
2. âœ… Atualizar assinatura de `SstableReader::open()`
3. âœ… Refatorar `read_block()` para usar `CacheKey`
4. âœ… Remover campo antigo `block_cache: LruCache<...>`
5. âœ… Atualizar mÃ©todo `calculate_cache_capacity()` (nÃ£o Ã© mais necessÃ¡rio)

### **Fase 3: IntegraÃ§Ã£o na Engine** (1-2 horas)

1. âœ… Adicionar campo `block_cache` em `LsmEngine`
2. âœ… Criar cache em `LsmEngine::new()`
3. âœ… Passar cache para todos os `SstableReader::open()`
4. âœ… Atualizar mÃ©todo `flush()` para passar cache

### **Fase 4: Testes de IntegraÃ§Ã£o** (2-3 horas)

```rust
#[test]
fn test_shared_cache_across_sstables() {
    let dir = tempdir().unwrap();
    let config = create_test_config(dir.path());
    let cache = GlobalBlockCache::new(1, 4096);
    
    // Criar mÃºltiplas SSTables
    let sst1 = create_test_sstable(dir.path().join("1.sst"), &config, &cache);
    let sst2 = create_test_sstable(dir.path().join("2.sst"), &config, &cache);
    
    // Verificar que ambas usam o mesmo cache
    let stats_before = cache.stats();
    
    sst1.get("key1").unwrap();  // Popula cache
    let stats_after1 = cache.stats();
    assert_eq!(stats_after1.len, stats_before.len + 1);
    
    sst2.get("key2").unwrap();  // Popula cache
    let stats_after2 = cache.stats();
    assert_eq!(stats_after2.len, stats_after1.len + 1);
}

#[test]
fn test_memory_limit_respected() {
    // Criar engine com cache de 1MB
    let config = LsmConfig {
        storage: StorageConfig {
            block_cache_size_mb: 1,
            block_size: 4096,
            // ...
        },
        // ...
    };
    
    let engine = LsmEngine::new(config).unwrap();
    
    // Criar muitas SSTables
    for i in 0..100 {
        insert_and_flush(&engine, i);
    }
    
    let stats = engine.block_cache.stats();
    let max_blocks = (1 * 1024 * 1024) / 4096;
    
    // Cache nÃ£o deve exceder limite
    assert!(stats.len <= max_blocks);
}
```

### **Fase 5: Benchmarks** (1 hora)

```rust
// benches/cache_benchmark.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn bench_cache_hit(c: &mut Criterion) {
    let cache = GlobalBlockCache::new(64, 4096);
    let key = CacheKey::new(&PathBuf::from("test.sst"), 0);
    cache.put(key.clone(), vec![0u8; 4096]);
    
    c.bench_function("cache_hit", |b| {
        b.iter(|| {
            black_box(cache.get(&key));
        });
    });
}

fn bench_cache_miss(c: &mut Criterion) {
    let cache = GlobalBlockCache::new(64, 4096);
    
    c.bench_function("cache_miss", |b| {
        b.iter(|| {
            let key = CacheKey::new(&PathBuf::from("test.sst"), rand::random());
            black_box(cache.get(&key));
        });
    });
}
```

---

## âš ï¸ ConsideraÃ§Ãµes de SeguranÃ§a e Performance

### 1. ContenÃ§Ã£o de Lock

**Problema:** `Mutex` pode criar gargalo em workloads com muitos cache hits.

**MitigaÃ§Ã£o:** Por enquanto, usar `Mutex` simples. Em otimizaÃ§Ã£o futura:
- Considerar `parking_lot::Mutex` (mais rÃ¡pido)
- Implementar cache sharded (dividir em N sub-caches)

### 2. Eviction Policy

**Comportamento:** LRU Ã© justo entre arquivos (nÃ£o privilegia nenhum arquivo especÃ­fico).

**ValidaÃ§Ã£o:** Adicionar teste para garantir eviction balanceada.

### 3. Clonagem de Vec

**Overhead:** `read_block()` retorna `Vec<u8>`, entÃ£o clonamos o `Arc<Vec<u8>>`.

**Alternativa futura:** Retornar `Arc<Vec<u8>>` diretamente (breaking change na API).

---

## ğŸ“Š MÃ©tricas de Sucesso

### CritÃ©rios de AceitaÃ§Ã£o

- âœ… Cache Ãºnico compartilhado entre todas as SSTables
- âœ… Uso de memÃ³ria = `O(cache_size_mb)` independente do nÃºmero de arquivos
- âœ… Todos os testes unitÃ¡rios e de integraÃ§Ã£o passando
- âœ… Benchmarks mostram overhead < 5% vs cache individual
- âœ… `cargo clippy` sem warnings

### MÃ©tricas de MemÃ³ria

**Antes:**
```
10 SSTables Ã— 64MB = 640MB
100 SSTables Ã— 64MB = 6.4GB
```

**Depois:**
```
10 SSTables â†’ 64MB total
100 SSTables â†’ 64MB total
```

**ReduÃ§Ã£o:** 10x para 10 arquivos, 100x para 100 arquivos

---

## ğŸ”„ Compatibilidade

### Breaking Changes

âœ… **Sim** - A assinatura de `SstableReader::open()` muda:

```rust
// Antes
SstableReader::open(path, config)

// Depois
SstableReader::open(path, config, cache)
```

### MigraÃ§Ã£o

Todos os callers de `SstableReader::open()` precisam ser atualizados:
- `LsmEngine::new()`
- `LsmEngine::flush()`
- Testes em `src/storage/reader.rs`

---

## ğŸ“š ReferÃªncias

- [LRU Cache in Rust](https://docs.rs/lru/latest/lru/)
- [Arc vs Rc](https://doc.rust-lang.org/std/sync/struct.Arc.html)
- [RocksDB Block Cache](https://github.com/facebook/rocksdb/wiki/Block-Cache)

---

## âœ… Checklist Final

- [ ] Fase 1: Estrutura base implementada
- [ ] Fase 2: Reader refatorado
- [ ] Fase 3: Engine integrada
- [ ] Fase 4: Testes passando
- [ ] Fase 5: Benchmarks executados
- [ ] DocumentaÃ§Ã£o atualizada
- [ ] Code review interno
- [ ] PR criado contra `main`
- [ ] Issue #35 fechada
